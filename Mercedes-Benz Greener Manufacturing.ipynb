{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Prob Statement\n",
    "\n",
    "You are required to reduce the time that cars spend on the test bench. Others will work with a dataset representing different permutations of features in a Mercedes-Benz car to predict the time it takes to pass testing. Optimal algorithms will contribute to faster testing, resulting in lower carbon dioxide emissions without reducing Mercedes-Benzâ€™s standards.\n",
    "\n",
    "Following actions should be performed:\n",
    "\n",
    "--> If for any column(s), the variance is equal to zero, then you need to remove those variable(s).\n",
    "--> Check for null and unique values for test and train sets.\n",
    "--> Apply label encoder.\n",
    "--> Perform dimensionality reduction.\n",
    "--> Predict your test_df values using XGBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Loading Relevant Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Importing train & test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the ID column as index as it is not needed for prediction\n",
    "df_train.drop('ID',inplace=True,axis=1)\n",
    "df_test.drop('ID',inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['y', 'X0', 'X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X8', 'X10',\n",
      "       ...\n",
      "       'X375', 'X376', 'X377', 'X378', 'X379', 'X380', 'X382', 'X383', 'X384',\n",
      "       'X385'],\n",
      "      dtype='object', length=377)\n",
      "Index(['X0', 'X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X8', 'X10', 'X11',\n",
      "       ...\n",
      "       'X375', 'X376', 'X377', 'X378', 'X379', 'X380', 'X382', 'X383', 'X384',\n",
      "       'X385'],\n",
      "      dtype='object', length=376)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.columns)\n",
    "print(df_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4209, 377)\n",
      "(4209, 376)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Columns having variance == zero, and remove those variable(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['X11', 'X93', 'X107', 'X233', 'X235', 'X268', 'X289', 'X290',\n",
       "       'X293', 'X297', 'X330', 'X347'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Zero_var_col = df_train.var()[df_train.var()==0].index.values\n",
    "Zero_var_col"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Alternte way to do it\n",
    "\n",
    "df2_train = df_train.var(numeric_only = True)\n",
    "\n",
    "\n",
    "col_to_drop = []\n",
    "for items in df2_train.iteritems():\n",
    "    if items[1] == 0:\n",
    "        print(items[1])\n",
    "        col_to_drop.append(items[0])\n",
    "        \n",
    "print(col_to_drop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting the lables having var == 0\n",
    "df_train.drop(Zero_var_col,axis = 1,inplace=True)\n",
    "df_test.drop(Zero_var_col,axis = 1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['y', 'X0', 'X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X8', 'X10',\n",
       "       ...\n",
       "       'X375', 'X376', 'X377', 'X378', 'X379', 'X380', 'X382', 'X383', 'X384',\n",
       "       'X385'],\n",
       "      dtype='object', length=365)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross check\n",
    "df_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Check for null and unique values for test and train sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### a. Checking null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(df_train.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(df_test.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b. Checking unique values "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unique value of all the columns are verified as under, it can be observed that except for first 10 columns all other columns have only 0 & 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[130.81  88.53  76.26 ...  85.71 108.77  87.48]\n",
      "['k' 'az' 't' 'al' 'o' 'w' 'j' 'h' 's' 'n' 'ay' 'f' 'x' 'y' 'aj' 'ak' 'am'\n",
      " 'z' 'q' 'at' 'ap' 'v' 'af' 'a' 'e' 'ai' 'd' 'aq' 'c' 'aa' 'ba' 'as' 'i'\n",
      " 'r' 'b' 'ax' 'bc' 'u' 'ad' 'au' 'm' 'l' 'aw' 'ao' 'ac' 'g' 'ab']\n",
      "['v' 't' 'w' 'b' 'r' 'l' 's' 'aa' 'c' 'a' 'e' 'h' 'z' 'j' 'o' 'u' 'p' 'n'\n",
      " 'i' 'y' 'd' 'f' 'm' 'k' 'g' 'q' 'ab']\n",
      "['at' 'av' 'n' 'e' 'as' 'aq' 'r' 'ai' 'ak' 'm' 'a' 'k' 'ae' 's' 'f' 'd'\n",
      " 'ag' 'ay' 'ac' 'ap' 'g' 'i' 'aw' 'y' 'b' 'ao' 'al' 'h' 'x' 'au' 't' 'an'\n",
      " 'z' 'ah' 'p' 'am' 'j' 'q' 'af' 'l' 'aa' 'c' 'o' 'ar']\n",
      "['a' 'e' 'c' 'f' 'd' 'b' 'g']\n",
      "['d' 'b' 'c' 'a']\n",
      "['u' 'y' 'x' 'h' 'g' 'f' 'j' 'i' 'd' 'c' 'af' 'ag' 'ab' 'ac' 'ad' 'ae'\n",
      " 'ah' 'l' 'k' 'n' 'm' 'p' 'q' 's' 'r' 'v' 'w' 'o' 'aa']\n",
      "['j' 'l' 'd' 'h' 'i' 'a' 'g' 'c' 'k' 'e' 'f' 'b']\n",
      "['o' 'x' 'e' 'n' 's' 'a' 'h' 'p' 'm' 'k' 'd' 'i' 'v' 'j' 'b' 'q' 'w' 'g'\n",
      " 'y' 'l' 'f' 'u' 'r' 't' 'c']\n",
      "[0 1]\n",
      "[0 1]\n",
      "[1 0]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[1 0]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[1 0]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[1 0]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[1 0]\n",
      "[0 1]\n",
      "[1 0]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[1 0]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[1 0]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[1 0]\n",
      "[0 1]\n",
      "[1 0]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[1 0]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[1 0]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[1 0]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[1 0]\n",
      "[0 1]\n",
      "[1 0]\n",
      "[0 1]\n",
      "[1 0]\n",
      "[1 0]\n",
      "[1 0]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[1 0]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[1 0]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[1 0]\n",
      "[1 0]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[1 0]\n",
      "[0 1]\n",
      "[1 0]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[1 0]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[1 0]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[1 0]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[1 0]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[1 0]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[1 0]\n",
      "[1 0]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[1 0]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[1 0]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[1 0]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[1 0]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[1 0]\n",
      "[0 1]\n",
      "[1 0]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[1 0]\n",
      "[1 0]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[1 0]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[1 0]\n",
      "[0 1]\n",
      "[1 0]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[1 0]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[1 0]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[1 0]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[1 0]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[1 0]\n",
      "[0 1]\n",
      "[1 0]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[1 0]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[1 0]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[1 0]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[1 0]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "for i in df_train.columns:\n",
    "    print(df_train[i].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Apply label encoder on train & test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['X0', 'X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X8'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# identifying categorical columns\n",
    "label_columns = df_train.describe(include=['object']).columns.values\n",
    "label_columns"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# identifying categorical columns (Alternate method)\n",
    "cat_col = []\n",
    "for c in df_train.columns:\n",
    "    if df_train[c].dtype == 'object':\n",
    "        cat_col.append(c)\n",
    "        \n",
    "print(cat_col)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "for col in label_columns:\n",
    "    le.fit(df_train[col].append(df_test[col]).values)\n",
    "    df_train[col]= le.transform(df_train[col])\n",
    "    df_test[col]= le.transform(df_test[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['y', 'X0', 'X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X8', 'X10',\n",
       "       ...\n",
       "       'X375', 'X376', 'X377', 'X378', 'X379', 'X380', 'X382', 'X383', 'X384',\n",
       "       'X385'],\n",
       "      dtype='object', length=365)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([37, 24, 46, 11, 41, 49, 36, 34, 45, 40, 23, 32, 50, 51,  9, 10, 12,\n",
       "       52, 43, 18, 15, 48,  6,  0, 31,  8, 30, 16, 29,  1, 26, 17, 35, 44,\n",
       "       25, 22, 28, 47,  4, 19, 39, 38, 21, 14,  3, 33,  2], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cross checking if lables are encoded to numbers\n",
    "df_train['X0'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Performing dimentionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importing package & initializing the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA \n",
    "pca = PCA(n_components = 0.98,svd_solver='full')\n",
    "\n",
    "X = df_train.drop('y',axis=1)\n",
    "y = df_train['y']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing train test & split\n",
    "X_train , X_val , y_train , y_val = train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=0.98, random_state=None,\n",
       "  svd_solver='full', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.n_components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.40868988, 0.21758508, 0.13120081, 0.10783522, 0.08165248,\n",
       "       0.0140934 , 0.00660951, 0.00384659, 0.00260289, 0.00214378,\n",
       "       0.00209857, 0.00180388])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Predicting using XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_X_train = pd.DataFrame(pca.transform(X_train))\n",
    "pca_X_val = pd.DataFrame(pca.transform(X_val)) \n",
    "pca_test = pd.DataFrame(pca.transform(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the model\n",
    "model = xgb.XGBRegressor(objective='reg:linear',learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:55:29] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "       importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting the model\n",
    "model.fit(pca_X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict on the validaiton set\n",
    "pred_y_val = model.predict(pca_X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#capture the MSE to get a measure of how accurate the predictions were\n",
    "mse_score = mean_squared_error(y_val,pred_y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84.22703928013917\n"
     ]
    }
   ],
   "source": [
    "#print the MSE score\n",
    "print(mse_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
